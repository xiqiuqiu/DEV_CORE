揭秘 Claude Skills：你不知道的 5 个“反常识”亮点

如果你曾反复将复杂的指令粘贴给 AI，或者厌倦了为每个新任务“重新发明轮子”，那么你一定思考过：AI 的能力应该如何扩展？在主流认知中，为 AI 添加“工具”或“技能”，通常意味着编写一段代码，通过函数调用（Function Calling）或 API 接口，让语言模型遵循传统编程的逻辑。

然而，Anthropic 的 Claude Skills 却选择了一条截然不同、甚至可以说更巧妙的道路。它并非将语言模型强行塞进程序员的框架里，而是反其道而行之，让 AI 的能力扩展回归语言的本质。

本文将深入 Claude Skills 的底层设计，揭示其背后五个最令人惊讶、甚至有些“反常识”的核心亮点。读完之后，你或许会重新审视 AI 的“工具箱”究竟应该是什么样子。

---

1. 技能非代码，而是“打了激素”的提示词

大多数开发者在设想为 AI 添加一项“技能”时，脑海中浮现的几乎都是一个封装好的 Python 函数或是一个 API 端点。这套“函数调用”的思维模式已深入人心。然而，Anthropic 却采取了一种根本性的颠覆。

Claude Skills 的核心真相是：它们本质上并非可执行代码，而是通过提示词扩展 (prompt expansion) 和上下文修改 (context modification) 来运作的精密提示词模板。它们不直接执行任务并返回结果，而是通过向对话中注入领域知识和详细指令，来准备和引导 Claude 的后续推理。

正如技术专家 Han Lee 在其深度解析中所指出的：

Skills are not executable code. They do NOT run Python or JavaScript... Skills are specialized prompt templates that inject domain-specific instructions into the conversation context.

技能不是可执行代码。它们不运行 Python 或 JavaScript……技能是专门的提示词模板，用于将特定领域的指令注入到对话上下文中。

这代表了一种深刻的范式转变。开发者不再是为 AI 编写僵化的 API，而是在 crafting 可以被 AI 理解、组合和迭代的自然语言指令。知名技术博主 Simon Willison 也点明了这一点，他发现 Skills 的概念简单得惊人：

Skills are conceptually extremely simple: a skill is a Markdown file telling the model how to do something, optionally accompanied by extra documents and pre-written scripts that the model can run to help it accomplish the tasks described by the skill.

技能在概念上极其简单：一个技能就是一个 Markdown 文件，告诉模型如何做某事，可以选择性地附带额外的文档和预先编写的脚本，模型可以运行这些脚本来帮助它完成技能所描述的任务。

这种设计的巧妙之处在于，它没有强迫语言模型去适应传统的编程框架，而是将“指令”本身视为一种可组合、可重用的资源，从而充分利用了大型语言模型最核心的优势——自然语言理解。这是一种更接近语言本质的能力扩展方式。

2. 技能选择纯靠大模型推理，没有算法“捷径”

在任何一个常规系统中，当用户发出指令时，选择合适的工具都是一个经典的路由问题。系统通常会依赖明确的算法逻辑——例如分类器、嵌入向量搜索或关键词匹配——来将用户意图“路由”到正确的工具上。

Claude Skills 再次打破常规。它的选择机制完全依赖大模型自身的推理能力，不存在任何代码层面的算法捷径。

Han Lee 的核心论断一针见血：

There is no algorithmic skill selection or AI-powered intent detection at the code level. The decision-making happens entirely within Claude’s reasoning process based on the skill descriptions provided.

在代码层面，没有算法化的技能选择或由 AI 驱动的意图检测。决策完全发生在 Claude 基于所提供的技能描述的推理过程中。

这个机制的设计堪称神来之笔。想象一下，Claude 眼前其实只有一个名为 Skill 的“元工具”（meta-tool）。这个元工具的描述里，包含了一份清晰、简洁的所有可用技能的列表（名称和功能简介）。当用户提出请求时，Claude 就像阅读普通文本一样，通读这份列表，凭借其原生的语言理解能力，自行判断哪个技能最符合当前任务，然后调用这个唯一的 Skill 元工具，并将选中的技能名称作为参数传入，例如 Skill(command='pdf')。

这不仅是对模型能力的考验，更是一场关于未来 AI 架构的大胆赌注。Anthropic 押注的是，大型语言模型涌现出的复杂推理能力，最终将胜过那些脆弱、僵化的、由人类显式编程的路由逻辑。这体现了对 LLM 原始智能的极大信任。

3. 大道至简：简单的设计才是其核心优势

面对这种设计，一些人的第一反应可能是：“就一个 Markdown 文件加几个脚本？这未免也太简单了，甚至算不上一个正式的‘功能’。”

然而，正是这种极致的简洁性，构成了 Claude Skills 最强大的核心优势。技术博主 Simon Willison 在其博客中，将 Skills 的简洁与 Model Context Protocol (MCP) 的复杂性进行了对比。MCP 作为一个强大的协议，其复杂的规范也带来了更高的学习和实现成本。相比之下，Skills 的设计哲学更贴近语言模型的本质——“扔给它一些文本，让模型自己搞定”。

Willison 对此评价极高，他认为这种简洁性恰恰是其最激动人心之处：

The core simplicity of the skills design is why I’m so excited about it.

技能设计的核心简洁性正是我对其如此兴奋的原因。

这种简洁性为何如此强大？因为它极大地降低了创造、分享和迭代能力的门槛。任何人，即便不是专业的程序员，都可以通过编写一个 Markdown 文件来封装一套可重用的工作流或知识。这种易用性为技能生态的繁荣奠定了基础，使其有潜力催生出一个由社区驱动、爆炸式增长的能力市场——正如 Willison 预测的那样，一场“技能的寒武纪大爆发”。

4. 一套隐藏的“双通道”系统：同时与人类和 AI 沟通

在人机交互设计中，一个普遍存在的难题是：如何在保持用户界面简洁明了的同时，为 AI 提供完成任务所需的详尽、甚至冗长的指令？如果把给 AI 的所有指令都展示给用户，界面会变得混乱不堪；如果完全隐藏，用户又会感觉系统是一个不透明的“黑箱”。

Claude Skills 通过一个极其精妙的“双消息”系统解决了这个矛盾。Han Lee 的分析揭示，系统利用了一个名为 isMeta 的标志，实现了信息的双通道沟通，为两个不同的受众——人类和 AI——提供定制化的信息。

这个机制创造了两条并行的沟通渠道：

1. 面向人类的通道 (isMeta: false)：当一个技能被激活时，系统会注入一条对用户可见的消息。这条消息非常简短，通常使用 XML 标签包裹，用于向用户更新状态，保持透明度。例如，界面上会显示 <command-message>The "pdf" skill is loading</command-message>（“pdf”技能正在加载）。
2. 面向 AI 的通道 (isMeta: true)：与此同时，系统会注入另一条对用户隐藏的消息。这条消息包含了技能 SKILL.md 文件中的全部内容——一份给 Claude 的完整、详细的操作指南。它被发送给模型用于推理，但绝不会出现在用户的聊天界面上。

这是一个极其优雅的信息架构设计。它巧妙地将面向人类的“状态沟通”与面向 AI 的“指令沟通”分离，完美解决了 AI 交互中透明度与简洁性之间的冲突。这正是 Han Lee 所说的“为元工具设计的元提示词（Meta-prompting for meta-tools）”理念的绝佳体现：用 AI 最核心的机制（提示词）去管理其元能力（技能使用），构建了一个逻辑自洽且高效的系统。

5. “渐进式披露”：实现高效与扩展的秘诀

大型语言模型的上下文窗口是其最宝贵的资源。如果一个系统需要在对话开始时就将成百上千个可用技能的全部指令加载进来，上下文窗口会迅速被耗尽，系统也将因此而崩溃。

Claude Skills 采用了一种名为“渐进式披露”（Progressive Disclosure）的信息加载策略，确保了极致的令牌（token）效率。这种设计不仅是为了节省资源，更是让大规模技能生态成为可能的基石。

该策略通过三个层次实现：

1. 第一层：仅加载元数据。 在对话开始时，系统只会加载所有可用技能的元数据（名称和描述）。这部分信息作为 Skill 元工具描述的一部分常驻上下文，但消耗的 token 极少。正如 Simon Willison 所指出的，“每个技能仅占用几十个额外的 token”。为了进一步控制消耗，Han Lee 提到这个列表甚至还有一个 15000 个字符的预算上限，这迫使技能的描述必须简洁有效。
2. 第二层：按需加载核心指令。 只有当 Claude 决定触发某个特定技能时，系统才会去加载该技能的核心指令文件 SKILL.md 的完整内容，并将其注入上下文。
3. 第三层：按需加载外部资源。 即便在 SKILL.md 被加载后，其中引用的其他文件（如 scripts/ 目录下的脚本或 references/ 目录下的文档）也只会在被明确需要时，由 Claude 通过工具调用（如 Read 工具）按需加载。

这种分层加载的架构堪称智慧。它并非简单的效率优化，而是让整个 Skills 系统得以**扩展（scale）**的核心设计。没有它，技能系统将不具备可行性，一旦技能数量超过个位数，就会因上下文溢出而崩溃。正是“渐进式披露”这一 foundational design choice，为构建一个包含成百上千种技能的繁荣生态系统解锁了可能性。

---

结论：一种更接近语言本质的 AI 进化之路

Claude Skills 并非传统意义上的“工具调用”，而是一种全新的 AI 能力扩展范式。它的力量源于对简洁性的极致追求、对 LLM 纯粹推理能力的深刻信任，以及一系列巧妙到“反常识”的信息架构设计。它让我们看到，扩展 AI 能力的最佳路径，或许不是让 AI 更像程序员，而是让工具更像语言。

它也预示着一个未来：提示词与代码之间的界限将日益模糊。通过将可重用的“指令”和“推理模式”作为一等公民，Anthropic 不仅是在构建一个工具系统，更是在创造一个用于编码和共享人类知识与工作流的框架。这条道路，或许最终会比任何僵化的 API 都更具柔性和生命力。
